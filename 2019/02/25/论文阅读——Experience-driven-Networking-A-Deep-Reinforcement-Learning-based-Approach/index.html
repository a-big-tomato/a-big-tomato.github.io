<!DOCTYPE html>
<html>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      论文阅读——Experience-driven Networking: A Deep Reinforcement Learning based Approach  | 一只番茄 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="Aimee">
    
    

    <meta name="description" content="这篇文章将DRL用在了traffic engineering 上，作者不但实现了DDPG算法，而且针对traffic engineering 提出了两方面改进，并最后在随机和代表性的拓扑上进行实验">
<meta name="keywords" content="deep reinforcement learning,DDGP,traffic engineering">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读——Experience-driven Networking: A Deep Reinforcement Learning based Approach  | 一只番茄">
<meta property="og:url" content="http://yoursite.com/2019/02/25/论文阅读——Experience-driven-Networking-A-Deep-Reinforcement-Learning-based-Approach/index.html">
<meta property="og:site_name" content="一只番茄">
<meta property="og:description" content="这篇文章将DRL用在了traffic engineering 上，作者不但实现了DDPG算法，而且针对traffic engineering 提出了两方面改进，并最后在随机和代表性的拓扑上进行实验">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://s2.ax1x.com/2019/02/25/kI8wvV.md.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/02/25/kI8DDU.md.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/02/25/kI8c59.md.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/02/25/kI82CR.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/02/25/kI84KK.png">
<meta property="og:updated_time" content="2019-02-25T15:52:32.679Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="论文阅读——Experience-driven Networking: A Deep Reinforcement Learning based Approach  | 一只番茄">
<meta name="twitter:description" content="这篇文章将DRL用在了traffic engineering 上，作者不但实现了DDPG算法，而且针对traffic engineering 提出了两方面改进，并最后在随机和代表性的拓扑上进行实验">
<meta name="twitter:image" content="https://s2.ax1x.com/2019/02/25/kI8wvV.md.png">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>
<body>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">一只番茄</a></h1>
        <hr class="panel-cover__divider" />

        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">论文阅读——Experience-driven Networking: A Deep Reinforcement Learning based Approach </h1>

    

    <div class="post-meta">
      <time datetime="2019-02-25" class="post-meta__date date">2019-02-25</time> 

      <span class="post-meta__tags tags">

          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/DDGP/">DDGP</a>, <a class="tags-link" href="/tags/deep-reinforcement-learning/">deep reinforcement learning</a>, <a class="tags-link" href="/tags/traffic-engineering/">traffic engineering</a>
            </font>
          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <p>这篇文章将DRL用在了traffic engineering 上，作者不但实现了DDPG算法，而且针对traffic engineering 提出了两方面改进，并最后在随机和代表性的拓扑上进行实验<br><a id="more"></a><br>符号说明：</p>
<p><img src="https://s2.ax1x.com/2019/02/25/kI8wvV.md.png" alt="符号说明"><br>state:将每个session端到端的吞吐量和延迟作为state<br>$s = [(x<em>1,z_1),(x_2,z_2)….(x_k,z_k)]$<br>action space:<br>将每个session_k的每一条path分配到的比例作为动作<br>$a = [w</em>{11},w<em>{12},….w</em>{kj},w<em>{k|pk|}]$. 注意哦，$w</em>{k1}$,$w<em>{k2}$到w</em>{k|Pk|}的和为1（这很容易理解，session 总共有|Pk|条路，每一条路走一定比例，但加起来一定是1）<br>reward:<br>是所有session总共的利用率。这里用了个作者自定的函数$U(x_k,z_k) = U1(x_k)-\alpha U2(z_k)$</p>
<p><img src="https://s2.ax1x.com/2019/02/25/kI8DDU.md.png" alt="action &amp; reward"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">简单应用DDGP，效果并不好，原因在于1.DDGP没有明确的说明如何探索.2.DDGP在experience replay中采样用的是均一采样的方式。作者对这两方面进行了优化。</span><br></pre></td></tr></table></figure>
<p>Exploration：<br>作者提出用一个base TE solution 来指导探索。<br>以概率$\epsilon$，DRL智体选择动作$a<em>{base} + \epsilon \cdot N$，$a</em>{base}$是base TE solution.以$(1 - \epsilon)$的概率选择智体动作$a + \epsilon \cdot N$。$a$是actor network 的输出，$\epsilon$是可调参数，和其他论文中一样，随着episode 衰退。$N$ 是噪声<br>prioritized experience replay<br>大体和prioritized experience replay 差不多，优先级公式是：<br><img src="https://s2.ax1x.com/2019/02/25/kI8c59.md.png" alt="Prioritized experience replay"><br>具体算法流程：<br><img src="https://s2.ax1x.com/2019/02/25/kI82CR.png" alt="算法过程"><br>实验：<br>    实验上，作者在两个典型网络上实验，也在随机生成的20个nodes,80条links的拓扑上实验。每个拓扑随机生成20个sessions.每个session选三条最短路径作为备选路径，每条路径100Mbps,包在source node 是柏松分布，但在路径中间点上就不一定了。起初的滑动窗口大小为20Mbps,后期会随着traffic damand增加（we increased the traffic demand by sliding the window with a step size of 5Mbps for each run）用延迟和吞吐量以及utility function 来作为评价标准：<br><img src="https://s2.ax1x.com/2019/02/25/kI84KK.png" alt="评价标准"></p>

  </section>

  <section class="post-comments">

    <!-- 将评论系统（例如Disqus、多说、友言、畅言等）提供的代码片段粘贴在这里 -->
    
</section>


</article>


            <footer class="footer">

    <span class="footer__copyright">&copy; 2014-2015. | 由<a href="https://hexo.io/">Hexo</a>强力驱动 | 主题<a href="https://github.com/someus/huno">Huno</a></span>
    
</footer>
        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

    

    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
